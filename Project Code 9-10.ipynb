{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of Dueling DQN algorithm from RLLib to Pong Environment"
      ],
      "metadata": {
        "id": "ZU7A7RRZJbAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to set everything up by installing and importing all appropriate libraries for the algorithm to work correctly"
      ],
      "metadata": {
        "id": "ZTZmOCDyJkSf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb8GFQDZitX0"
      },
      "outputs": [],
      "source": [
        "# Uninstall conflicting versions if necessary\n",
        "!pip uninstall -y jax jaxlib flax numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install compatible versions line-by-line"
      ],
      "metadata": {
        "id": "8_4MgVXgjAyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"jax==0.4.23\" \"jaxlib==0.4.23\" \"flax==0.7.2\""
      ],
      "metadata": {
        "id": "jBJ8ksczi9YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy==1.24.4\""
      ],
      "metadata": {
        "id": "x9Uzj_L7i9cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"ray[rllib]==2.9.0\""
      ],
      "metadata": {
        "id": "TyfTSATbi9fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gym[atari]==0.26.2\" ale-py==0.8.1"
      ],
      "metadata": {
        "id": "4x8N27Rti9nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gym[atari]\" \"autorom[accept-rom-license]\""
      ],
      "metadata": {
        "id": "AK0MAVRmjMVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "id": "-q0Vfl9UjMj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Force reinstall of setuptools which includes pkg_resources\n",
        "!pip install --force-reinstall \"setuptools==65.5.0\""
      ],
      "metadata": {
        "id": "iCRy1I9OjkTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gym atari + autoRom\n",
        "!pip install \"gym[atari]\" \"autorom[accept-rom-license]\""
      ],
      "metadata": {
        "id": "1KNzfyRojkVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "id": "D5sZgGqdjkXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[atari] autorom[accept-rom-license]"
      ],
      "metadata": {
        "id": "A66HBGNZkA9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari]"
      ],
      "metadata": {
        "id": "ChATSTxCkBBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pkg_resources\n",
        "from pkg_resources._vendor.packaging.version import parse as parse_version"
      ],
      "metadata": {
        "id": "oYoE3nIbkOwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "from ray.rllib.algorithms.dqn import DQNConfig\n",
        "\n",
        "#ray.init(ignore_reinit_error=True)"
      ],
      "metadata": {
        "id": "EELtOW7ckTrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import gymnasium as gym\n",
        "from ray import tune\n",
        "from gymnasium.spaces import Box, Discrete\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-sDf6xybjPgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the environment\n",
        "tune.register_env(\"Pong-ram-v0\", lambda config: gym.make(\"Pong-ram-v0\"))"
      ],
      "metadata": {
        "id": "tluqcOgGmWDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Dueling DQN\n",
        "config = (\n",
        "    DQNConfig()\n",
        "    .environment(env=\"Pong-ram-v0\", env_config={\"max_episode_steps\": 500})\n",
        "    .rollouts(num_rollout_workers=0)\n",
        "    .training(\n",
        "        dueling=True,\n",
        "# it was tried to implement the code also with the below parameters,\n",
        "# but the running time was taking too long so it was opted against it\n",
        "#        train_batch_size=256,\n",
        "#        lr=1e-4,\n",
        "    )\n",
        "#    .exploration(\n",
        "#        exploration_config={\n",
        "#            \"type\": \"EpsilonGreedy\",\n",
        "#            \"initial_epsilon\": 1.0,\n",
        "#            \"final_epsilon\": 0.1,\n",
        "#            \"epsilon_timesteps\": 20000,\n",
        "#        }\n",
        "#    )\n",
        ")\n",
        "\n",
        "# Build agent\n",
        "algo = config.build()\n",
        "\n",
        "# Train agent\n",
        "rewards = []\n",
        "for i in range(100):\n",
        "    result = algo.train()\n",
        "    rewards.append(result[\"episode_reward_mean\"])\n",
        "    print(f\"Iteration: {i}, Reward: {result['episode_reward_mean']}\")"
      ],
      "metadata": {
        "id": "-e8TZCqMjPke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save rewards\n",
        "pd.DataFrame(rewards).to_csv(\"dueling_dqn_rewards.csv\")"
      ],
      "metadata": {
        "id": "26KHDTKAjPoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "env = gym.make(\"Pong-ram-v0\")\n",
        "n_episodes = 100\n",
        "net_scores = []\n",
        "\n",
        "for episode in range(1, n_episodes + 1):\n",
        "    obs, info = env.reset()\n",
        "    agent_pts, opponent_pts = 0, 0\n",
        "    terminated = False\n",
        "\n",
        "    while not terminated:\n",
        "        action = algo.compute_single_action(obs, explore=False)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        # Track points\n",
        "        if reward == 1:\n",
        "            agent_pts += 1\n",
        "        elif reward == -1:\n",
        "            opponent_pts += 1\n",
        "\n",
        "    score_diff = agent_pts - opponent_pts\n",
        "    net_scores.append(score_diff)\n",
        "\n",
        "    # Log every 10 episodes\n",
        "    if episode % 10 == 0 or episode == n_episodes:\n",
        "        print(f\"[Episode {episode}] Agent: {agent_pts}, Opponent: {opponent_pts}, Net Score: {score_diff}\")"
      ],
      "metadata": {
        "id": "9eJ3z2Xzi5A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = list(range(1, len(rewards) + 1))\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(iterations, rewards, marker='.', linestyle='-')\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Average Reward\")\n",
        "plt.title(\"Dueling DQN Average Reward per Iteration on Pong (during training)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "upk8ChvjHKnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = list(range(1, len(net_scores)+1))\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(episodes, net_scores, marker='.', linestyle='-')\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Average Reward\")\n",
        "plt.title(\"Dueling DQN Average Reward per Episode on Pong (during evaluation)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KalYY-4hi5F3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}